<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Mathematical Foundations - Quantum Notes</title>

  <link rel="icon" type="image/png" href="../../img/mathematical_foundations_favicon.png">
  <link
    rel="stylesheet"
    href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    crossorigin="anonymous"
  />

  <!-- Font Awesome for icons -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" crossorigin="anonymous" />

  <!-- KaTeX for math rendering -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>

  <link
    href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;500;600;700&family=Nunito:wght@300;400;600;700&family=Space+Mono&display=swap"
    rel="stylesheet"
  />

  <style>
    :root {
      --primary-color: #2b6cb0;
      --primary-dark: #1a365d;
      --primary-light: #4299e1;
      --secondary-color: #ecc94b;
      --secondary-light: #faf089;
      --accent-color: #38b2ac;
      --accent-light: #81e6d9;
      --background-dark: #0d0f18;
      --background-card: #1e2233;
      --text-light: #e2e8f0;
      --text-bright: #ffffff;
      --glow-shadow: 0 0 15px rgba(66, 153, 225, 0.8);
      --card-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);
      
      /* Section backgrounds */
      --bg-gradient-1: linear-gradient(120deg, #1a365d, #2b6cb0);
      --bg-gradient-2: linear-gradient(120deg, #234e52, #38b2ac);
    }

    body {
      background: radial-gradient(ellipse at bottom, #1a202c 0%, #0d1117 100%);
      color: var(--text-light);
      font-family: 'Nunito', sans-serif;
      position: relative;
      overflow-x: hidden;
      min-height: 100vh;
      margin: 0;
      padding: 0;
      line-height: 1.7;
    }

    .navbar {
      background: linear-gradient(45deg, var(--primary-dark), var(--primary-color));
      box-shadow: var(--glow-shadow);
      z-index: 999;
      padding: 0.8rem 1rem;
    }

    .back-to-site {
      font-size: 1.2rem;
      font-weight: 700;
      text-decoration: none;
      color: var(--primary-color);
      border: 2px solid var(--primary-color);
      padding: 5px 10px;
      border-radius: 5px;
      background-color: #e4e4e4;
      transition: all 0.3s ease;
      display: inline-flex;
      align-items: center;
      gap: 8px;
    }

    .back-to-site:hover {
      color: var(--secondary-color);
      background-color: #1e1e1e;
      text-shadow: 0 0 15px rgba(255, 204, 0, 1);
    }

    .back-to-notes {
      font-size: 1.1rem;
      color: var(--text-light);
      display: inline-flex;
      align-items: center;
      gap: 8px;
      margin-left: 15px;
      text-decoration: none;
      padding: 5px 10px;
      border-radius: 5px;
      transition: all 0.3s ease;
    }

    .back-to-notes:hover {
      background: rgba(255, 255, 255, 0.1);
      text-decoration: none;
      color: var(--text-bright);
    }

    .title-container {
      position: relative;
      background: url('../../img/math_banner.jpg') center / cover no-repeat;
      height: 340px;
      display: flex;
      align-items: center;
      justify-content: center;
      overflow: hidden;
      text-align: center;
      border-bottom: 2px solid var(--primary-color);
    }

    .title-container::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.5);
      z-index: 1;
    }

    .title-container::after {
      content: '';
      position: absolute;
      width: 200%;
      height: 150%;
      background: radial-gradient(circle, rgba(66, 153, 225, 0.3) 20%, transparent 70%);
      top: -50%;
      left: -50%;
      animation: pulse 8s infinite ease-in-out alternate;
    }

    .title-content {
      position: relative;
      z-index: 10;
    }

    h1 {
      font-size: 3.5rem;
      font-family: 'Orbitron', sans-serif;
      color: #fff;
      text-shadow:
        0 0 10px rgba(66, 153, 225, 1),
        0 0 20px rgba(66, 153, 225, 0.7);
      z-index: 2;
      margin: 0;
    }

    .subtitle {
      font-size: 1.4rem;
      color: var(--text-bright);
      max-width: 700px;
      margin: 1rem auto;
      text-shadow: 0 0 10px rgba(0, 0, 0, 0.5);
    }

    .section-title {
      font-family: 'Orbitron', sans-serif;
      font-size: 2.2rem;
      text-transform: uppercase;
      margin-top: 3rem;
      margin-bottom: 1.5rem;
      text-shadow: 2px 2px 10px rgba(66, 153, 225, 0.6);
      color: var(--primary-light);
      position: relative;
      letter-spacing: 2px;
    }

    .section-title::after {
      content: "";
      display: block;
      width: 80px;
      height: 4px;
      background: linear-gradient(90deg, transparent, var(--primary-light), transparent);
      margin: 0.8rem 0;
      border-radius: 2px;
    }

    .subsection-title {
      font-family: 'Orbitron', sans-serif;
      font-size: 1.6rem;
      color: var(--secondary-color);
      margin-top: 2.5rem;
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 10px;
    }

    .subsection-title i {
      color: var(--accent-color);
    }

    .math-note {
      background-color: rgba(30, 34, 51, 0.7);
      border-left: 4px solid var(--primary-light);
      padding: 1.5rem;
      margin: 2rem 0;
      border-radius: 0 8px 8px 0;
      box-shadow: var(--card-shadow);
    }

    .theorem {
      background-color: rgba(43, 108, 176, 0.15);
      border-left: 4px solid var(--primary-light);
      padding: 1.5rem;
      margin: 2rem 0;
      border-radius: 0 8px 8px 0;
      box-shadow: var(--card-shadow);
    }

    .definition {
      background-color: rgba(56, 178, 172, 0.15);
      border-left: 4px solid var(--accent-color);
      padding: 1.5rem;
      margin: 2rem 0;
      border-radius: 0 8px 8px 0;
      box-shadow: var(--card-shadow);
    }

    .example {
      background-color: rgba(236, 201, 75, 0.15);
      border-left: 4px solid var(--secondary-color);
      padding: 1.5rem;
      margin: 2rem 0;
      border-radius: 0 8px 8px 0;
      box-shadow: var(--card-shadow);
    }

    .theorem-title, .definition-title, .example-title {
      font-weight: 700;
      text-transform: uppercase;
      letter-spacing: 1px;
      margin-bottom: 1rem;
      display: block;
    }

    .theorem-title {
      color: var(--primary-light);
    }

    .definition-title {
      color: var(--accent-color);
    }

    .example-title {
      color: var(--secondary-color);
    }

    .math-content {
      margin-top: 2rem;
      line-height: 1.8;
    }

    code {
      font-family: 'Space Mono', monospace;
      background-color: rgba(0, 0, 0, 0.3);
      color: var(--accent-light);
      padding: 0.1rem 0.3rem;
      border-radius: 3px;
    }

    .note-navigation {
      display: flex;
      justify-content: space-between;
      margin-top: 4rem;
      padding-top: 2rem;
      border-top: 1px solid rgba(255, 255, 255, 0.1);
    }

    .nav-link {
      display: flex;
      align-items: center;
      padding: 0.8rem 1.5rem;
      background-color: rgba(30, 34, 51, 0.7);
      border-radius: 8px;
      text-decoration: none;
      color: var(--text-light);
      transition: all 0.3s ease;
    }

    .nav-link:hover {
      background-color: var(--primary-dark);
      transform: translateY(-3px);
      text-decoration: none;
      color: var(--text-bright);
      box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3);
    }

    .nav-prev {
      flex-direction: row;
    }

    .nav-next {
      flex-direction: row-reverse;
    }

    .nav-text {
      display: flex;
      flex-direction: column;
    }

    .nav-label {
      font-size: 0.8rem;
      opacity: 0.7;
    }

    .nav-title {
      font-weight: 600;
    }

    .nav-prev i {
      margin-right: 10px;
    }

    .nav-next i {
      margin-left: 10px;
    }

    .math-figure {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin: 2rem 0;
      padding: 1.5rem;
      background-color: rgba(255, 255, 255, 0.03);
      border-radius: 8px;
      box-shadow: var(--card-shadow);
    }

    .math-figure img {
      max-width: 100%;
      border-radius: 4px;
    }

    .math-figure figcaption {
      margin-top: 1rem;
      font-style: italic;
      opacity: 0.7;
      text-align: center;
    }

    .katex {
      font-size: 1.1em;
    }

    .katex-display {
      overflow-x: auto;
      overflow-y: hidden;
      padding: 0.5rem 0;
    }

    .scrollable-math {
      overflow-x: auto;
      margin: 1.5rem 0;
    }

    footer {
      background: linear-gradient(45deg, var(--primary-dark), var(--primary-color));
      padding: 2rem;
      text-align: center;
      font-size: 1.1rem;
      color: white;
      box-shadow: 0 -5px 15px rgba(0, 0, 0, 0.3);
      position: relative;
      margin-top: 4rem;
    }

    footer::before {
      content: '';
      position: absolute;
      top: -10px;
      left: 0;
      right: 0;
      height: 10px;
      background: linear-gradient(90deg, var(--primary-dark), var(--accent-color), var(--primary-dark));
    }

    footer p {
      margin: 0;
      text-shadow: 0 0 5px rgba(0, 0, 0, 0.3);
    }

    .table-of-contents {
      background-color: rgba(30, 34, 51, 0.7);
      border-radius: 8px;
      padding: 1.5rem;
      margin: 2rem 0;
      box-shadow: var(--card-shadow);
    }

    .toc-title {
      font-family: 'Orbitron', sans-serif;
      font-size: 1.4rem;
      color: var(--primary-light);
      margin-bottom: 1rem;
      display: flex;
      align-items: center;
      gap: 10px;
    }

    .toc-list {
      list-style-type: none;
      padding-left: 0;
    }

    .toc-list li {
      padding: 0.4rem 0;
      border-bottom: 1px solid rgba(255, 255, 255, 0.1);
      display: flex;
    }

    .toc-list li:last-child {
      border-bottom: none;
    }

    .toc-list a {
      color: var(--text-light);
      text-decoration: none;
      transition: all 0.2s ease;
      display: flex;
      align-items: center;
      width: 100%;
    }

    .toc-list a:hover {
      color: var(--primary-light);
      transform: translateX(5px);
    }

    .toc-list a i {
      margin-right: 8px;
      font-size: 0.8rem;
      color: var(--accent-color);
    }

    .toc-section-number {
      background: rgba(66, 153, 225, 0.2);
      color: var(--primary-light);
      border-radius: 50%;
      width: 28px;
      height: 28px;
      display: flex;
      align-items: center;
      justify-content: center;
      margin-right: 12px;
      font-weight: 600;
      font-size: 0.9rem;
      flex-shrink: 0;
    }

    /* Animations */
    @keyframes pulse {
      0% {
        transform: scale(1);
        opacity: 0.5;
      }
      100% {
        transform: scale(1.3);
        opacity: 0.1;
      }
    }

    /* Custom Scrollbar */
    ::-webkit-scrollbar {
      width: 10px;
    }

    ::-webkit-scrollbar-track {
      background: rgba(30, 30, 30, 0.7);
    }

    ::-webkit-scrollbar-thumb {
      background: linear-gradient(var(--primary-color), var(--primary-dark));
      border-radius: 5px;
    }

    ::-webkit-scrollbar-thumb:hover {
      background: linear-gradient(var(--primary-dark), var(--primary-color));
    }

    @media (max-width: 768px) {
      .title-container {
        height: 280px;
      }
      
      h1 {
        font-size: 2.5rem;
      }
      
      .subtitle {
        font-size: 1.1rem;
      }
      
      .section-title {
        font-size: 1.8rem;
      }
      
      .subsection-title {
        font-size: 1.4rem;
      }
      
      .note-navigation {
        flex-direction: column;
        gap: 1rem;
      }
      
      .nav-prev, .nav-next {
        width: 100%;
      }
    }
  </style>
</head>
<body>
  <nav class="navbar navbar-expand-md navbar-dark">
    <div class="container-fluid">
      <a href="../../index.html" class="back-to-site">
        <i class="fas fa-arrow-left"></i> Back to Main Site
      </a>
      <a href="../quantum.html" class="back-to-notes">
        <i class="fas fa-book"></i> Quantum Notes
      </a>
    </div>
  </nav>
  
  <div class="title-container">
    <div class="title-content">
      <h1>Mathematical Foundations</h1>
      <div class="subtitle">The elegant mathematical structures that serve as the language of quantum mechanics</div>
    </div>
  </div>

  <div class="container py-4">
    <div class="table-of-contents">
      <div class="toc-title">
        <i class="fas fa-list"></i> Contents
      </div>
      <ul class="toc-list">
        <li>
          <a href="#introduction">
            <div class="toc-section-number">1</div>
            <span>Introduction to Mathematical Foundations</span>
          </a>
        </li>
        <li>
          <a href="#complex-numbers">
            <div class="toc-section-number">2</div>
            <span>Complex Numbers and Analysis</span>
          </a>
        </li>
        <li>
          <a href="#linear-algebra">
            <div class="toc-section-number">3</div>
            <span>Linear Algebra Fundamentals</span>
          </a>
        </li>
        <li>
          <a href="#vector-spaces">
            <div class="toc-section-number">4</div>
            <span>Vector Spaces and Inner Products</span>
          </a>
        </li>
        <li>
          <a href="#hilbert-spaces">
            <div class="toc-section-number">5</div>
            <span>Hilbert Spaces</span>
          </a>
        </li>
        <li>
          <a href="#dirac-notation">
            <div class="toc-section-number">6</div>
            <span>Dirac Notation</span>
          </a>
        </li>
        <li>
          <a href="#linear-operators">
            <div class="toc-section-number">7</div>
            <span>Linear Operators</span>
          </a>
        </li>
        <li>
          <a href="#eigenvectors">
            <div class="toc-section-number">8</div>
            <span>Eigenvalues and Eigenvectors</span>
          </a>
        </li>
        <li>
          <a href="#tensor-products">
            <div class="toc-section-number">9</div>
            <span>Tensor Products</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="math-content">
      <section id="introduction">
        <h2 class="section-title">Introduction to Mathematical Foundations</h2>
        
        <p>
          Mathematics provides the language and framework that allows us to formulate, manipulate, and understand the principles of quantum mechanics. Unlike classical physics, which often relies on intuitive concepts from everyday experience, quantum mechanics requires a more abstract mathematical approach to describe phenomena that have no classical analogues.
        </p>
        
        <p>
          In this note, we will explore the essential mathematical tools used in quantum mechanics, beginning with the foundational concepts and gradually building up to more sophisticated structures. Our journey will encompass complex numbers, linear algebra, vector spaces, Hilbert spaces, and the elegant Dirac notation that simplifies many quantum mechanical calculations.
        </p>
        
        <div class="math-note">
          <p>
            <strong>Historical Context:</strong> The development of quantum mechanics in the early 20th century coincided with advancements in abstract mathematics, particularly in functional analysis and linear algebra. Many mathematical structures that were initially developed for pure mathematical purposes found their perfect application in the emerging field of quantum mechanics. This remarkable correspondence between abstract mathematics and physical reality continues to be one of the most fascinating aspects of quantum theory.
          </p>
        </div>
      </section>

      <section id="complex-numbers">
        <h2 class="section-title">Complex Numbers and Analysis</h2>
        
        <p>
          Complex numbers form the foundation of quantum mechanics. Unlike classical mechanics, which primarily uses real numbers, quantum mechanics fundamentally requires complex numbers to describe quantum states and their evolution.
        </p>
        
        <h3 class="subsection-title"><i class="fas fa-square-root-alt"></i> Basic Complex Numbers</h3>
        
        <p>
          A complex number \(z\) is typically expressed as:
        </p>
        
        <div class="scrollable-math">
          \[z = a + bi\]
        </div>
        
        <p>
          where \(a\) and \(b\) are real numbers, and \(i\) is the imaginary unit defined by the property \(i^2 = -1\). The number \(a\) is called the real part of \(z\), denoted by \(\text{Re}(z)\), and \(b\) is called the imaginary part, denoted by \(\text{Im}(z)\).
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Complex Conjugate</span>
          <p>
            The complex conjugate of a complex number \(z = a + bi\), denoted by \(z^*\) or \(\overline{z}\), is defined as:
            \[z^* = a - bi\]
          </p>
        </div>
        
        <p>
          Complex numbers can be represented geometrically in the complex plane, where the horizontal axis represents the real part and the vertical axis represents the imaginary part. This representation allows us to interpret complex numbers as points or vectors in a two-dimensional plane.
        </p>
        
        <h3 class="subsection-title"><i class="fas fa-exchange-alt"></i> Polar Form</h3>
        
        <p>
          Complex numbers can also be expressed in polar form:
        </p>
        
        <div class="scrollable-math">
          \[z = re^{i\theta} = r(\cos\theta + i\sin\theta)\]
        </div>
        
        <p>
          where \(r = |z| = \sqrt{a^2 + b^2}\) is the modulus or absolute value of \(z\), and \(\theta = \arg(z) = \arctan(b/a)\) is the argument or phase of \(z\). The polar form is particularly useful in quantum mechanics, especially when dealing with wave functions and phase factors.
        </p>
        
        <div class="theorem">
          <span class="theorem-title">Theorem: Euler's Formula</span>
          <p>
            For any real number \(\theta\):
            \[e^{i\theta} = \cos\theta + i\sin\theta\]
          </p>
          <p>
            This elegant relation connects complex exponentials to trigonometric functions and is fundamental in the mathematical description of oscillations and waves in quantum mechanics.
          </p>
        </div>
        
        <div class="example">
          <span class="example-title">Example: Complex Operations</span>
          <p>Consider the complex numbers \(z_1 = 3 + 4i\) and \(z_2 = 1 - 2i\).</p>
          <p>Addition: \(z_1 + z_2 = (3 + 4i) + (1 - 2i) = 4 + 2i\)</p>
          <p>Multiplication: \(z_1 \cdot z_2 = (3 + 4i)(1 - 2i) = 3 - 6i + 4i - 8i^2 = 3 - 2i + 8 = 11 - 2i\)</p>
          <p>Modulus: \(|z_1| = \sqrt{3^2 + 4^2} = \sqrt{25} = 5\)</p>
          <p>Complex conjugate: \(z_1^* = 3 - 4i\)</p>
        </div>
      </section>

      <section id="linear-algebra">
        <h2 class="section-title">Linear Algebra Fundamentals</h2>
        
        <p>
          Linear algebra provides the mathematical framework for describing quantum states, observables, and their transformations. It deals with vector spaces, linear transformations, matrices, and related concepts.
        </p>
        
        <h3 class="subsection-title"><i class="fas fa-vector-square"></i> Vectors and Matrices</h3>
        
        <p>
          In linear algebra, a vector is an element of a vector space. In the context of finite-dimensional spaces, vectors can be represented as ordered collections of numbers (components). For example, a vector \(\vec{v}\) in \(\mathbb{R}^3\) might be written as:
        </p>
        
        <div class="scrollable-math">
          \[\vec{v} = \begin{pmatrix} v_1 \\ v_2 \\ v_3 \end{pmatrix}\]
        </div>
        
        <p>
          A matrix is a rectangular array of numbers. An \(m \times n\) matrix \(A\) has \(m\) rows and \(n\) columns:
        </p>
        
        <div class="scrollable-math">
          \[A = \begin{pmatrix} 
          a_{11} & a_{12} & \cdots & a_{1n} \\
          a_{21} & a_{22} & \cdots & a_{2n} \\
          \vdots & \vdots & \ddots & \vdots \\
          a_{m1} & a_{m2} & \cdots & a_{mn}
          \end{pmatrix}\]
        </div>
        
        <p>
          Matrices represent linear transformations between vector spaces. The application of a matrix \(A\) to a vector \(\vec{v}\) is denoted by \(A\vec{v}\) and results in another vector.
        </p>
        
        <div class="theorem">
          <span class="theorem-title">Theorem: Matrix Multiplication</span>
          <p>
            If \(A\) is an \(m \times n\) matrix and \(B\) is an \(n \times p\) matrix, then their product \(C = AB\) is an \(m \times p\) matrix whose elements are given by:
            \[c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}\]
          </p>
        </div>
        
        <div class="definition">
          <span class="definition-title">Definition: Special Types of Matrices</span>
          <ul>
            <li><strong>Identity Matrix (\(I\)):</strong> A square matrix with ones on the diagonal and zeros elsewhere.</li>
            <li><strong>Diagonal Matrix:</strong> A square matrix with non-zero elements only on the diagonal.</li>
            <li><strong>Hermitian Matrix:</strong> A square matrix equal to its conjugate transpose: \(A = A^\dagger\) (where \(A^\dagger = (A^*)^T\)).</li>
            <li><strong>Unitary Matrix:</strong> A square matrix whose inverse equals its conjugate transpose: \(U^{-1} = U^\dagger\).</li>
          </ul>
        </div>
        
        <p>
          Hermitian and unitary matrices are particularly important in quantum mechanics, as they represent observables and transformations between quantum states, respectively.
        </p>
      </section>

      <section id="vector-spaces">
        <h2 class="section-title">Vector Spaces and Inner Products</h2>
        
        <p>
          A vector space \(V\) over a field \(F\) (typically \(\mathbb{R}\) or \(\mathbb{C}\)) is a set equipped with two operations: vector addition and scalar multiplication, satisfying certain axioms that formalize the intuitive properties of vectors.
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Vector Space</span>
          <p>
            A vector space \(V\) over a field \(F\) consists of a set of elements (vectors) with two operations:
          </p>
          <ol>
            <li>Vector addition: \(V \times V \rightarrow V\), denoted by \(+\)</li>
            <li>Scalar multiplication: \(F \times V \rightarrow V\), denoted by juxtaposition</li>
          </ol>
          <p>
            These operations must satisfy the following axioms for all vectors \(u, v, w \in V\) and scalars \(a, b \in F\):
          </p>
          <ol>
            <li>Closure under addition: \(u + v \in V\)</li>
            <li>Commutativity of addition: \(u + v = v + u\)</li>
            <li>Associativity of addition: \((u + v) + w = u + (v + w)\)</li>
            <li>Existence of zero vector: There exists \(0 \in V\) such that \(v + 0 = v\) for all \(v \in V\)</li>
            <li>Existence of additive inverse: For each \(v \in V\), there exists \(-v \in V\) such that \(v + (-v) = 0\)</li>
            <li>Closure under scalar multiplication: \(av \in V\) for all \(a \in F\) and \(v \in V\)</li>
            <li>Distributivity of scalar multiplication over vector addition: \(a(u + v) = au + av\)</li>
            <li>Distributivity of scalar addition over vector multiplication: \((a + b)v = av + bv\)</li>
            <li>Compatibility of scalar multiplication: \(a(bv) = (ab)v\)</li>
            <li>Scalar identity: \(1v = v\) where \(1\) is the multiplicative identity in \(F\)</li>
          </ol>
        </div>

        <h3 class="subsection-title"><i class="fas fa-arrows-alt"></i> Basis and Dimension</h3>
        
        <p>
          A set of vectors \(\{v_1, v_2, \ldots, v_n\}\) in a vector space \(V\) is linearly independent if the only solution to the equation \(c_1 v_1 + c_2 v_2 + \ldots + c_n v_n = 0\) is \(c_1 = c_2 = \ldots = c_n = 0\).
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Basis</span>
          <p>
            A basis for a vector space \(V\) is a linearly independent set of vectors that spans \(V\). In other words, every vector in \(V\) can be expressed uniquely as a linear combination of basis vectors.
          </p>
        </div>
        
        <p>
          The dimension of a vector space is the number of vectors in any basis for that space. For example, \(\mathbb{R}^3\) has dimension 3, and the standard basis consists of the three vectors:
        </p>
        
        <div class="scrollable-math">
          \[\hat{i} = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}, \quad
          \hat{j} = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}, \quad
          \hat{k} = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}\]
        </div>
        
        <h3 class="subsection-title"><i class="fas fa-dot-circle"></i> Inner Product Spaces</h3>
        
        <p>
          An inner product space is a vector space equipped with an inner product, which is a function that assigns a scalar to each pair of vectors and satisfies certain properties.
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Inner Product</span>
          <p>
            An inner product on a vector space \(V\) over \(\mathbb{C}\) is a function \(\langle \cdot, \cdot \rangle: V \times V \rightarrow \mathbb{C}\) that satisfies:
          </p>
          <ol>
            <li>Linearity in the first argument: \(\langle au + bv, w \rangle = a\langle u, w \rangle + b\langle v, w \rangle\) for all \(u, v, w \in V\) and \(a, b \in \mathbb{C}\)</li>
            <li>Conjugate symmetry: \(\langle v, w \rangle = \langle w, v \rangle^*\) for all \(v, w \in V\)</li>
            <li>Positive definiteness: \(\langle v, v \rangle > 0\) for all \(v \neq 0\)</li>
          </ol>
        </div>
        
        <p>
          The standard inner product on \(\mathbb{C}^n\) is given by:
        </p>
        
        <div class="scrollable-math">
          \[\langle v, w \rangle = \sum_{i=1}^{n} v_i^* w_i\]
        </div>
        
        <p>
          where \(v_i^*\) is the complex conjugate of \(v_i\).
        </p>
        
        <p>
          The inner product induces a norm (a measure of the "length" of a vector) defined by:
        </p>
        
        <div class="scrollable-math">
          \[||v|| = \sqrt{\langle v, v \rangle}\]
        </div>
        
        <p>
          Two vectors \(v\) and \(w\) are orthogonal if \(\langle v, w \rangle = 0\). A set of vectors \(\{v_1, v_2, \ldots, v_n\}\) is orthonormal if they are mutually orthogonal and each has unit norm:
        </p>
        
        <div class="scrollable-math">
          \[\langle v_i, v_j \rangle = \delta_{ij} = 
          \begin{cases} 
          1 & \text{if } i = j \\
          0 & \text{if } i \neq j
          \end{cases}\]
        </div>
        
        <div class="theorem">
          <span class="theorem-title">Theorem: Cauchy-Schwarz Inequality</span>
          <p>
            For any vectors \(v\) and \(w\) in an inner product space:
            \[|\langle v, w \rangle| \leq ||v|| \cdot ||w||\]
            Equality holds if and only if one vector is a scalar multiple of the other.
          </p>
        </div>
        
        <div class="example">
          <span class="example-title">Example: Orthogonal Projections</span>
          <p>
            If \(v\) is a vector and \(w\) is a unit vector (\(||w|| = 1\)), then the orthogonal projection of \(v\) onto \(w\) is given by:
            \[\text{proj}_w v = \langle v, w \rangle w\]
          </p>
          <p>
            This projection represents the component of \(v\) in the direction of \(w\). The orthogonal complement is given by:
            \[v - \text{proj}_w v = v - \langle v, w \rangle w\]
          </p>
        </div>
      </section>

      <section id="hilbert-spaces">
        <h2 class="section-title">Hilbert Spaces</h2>
        
        <p>
          A Hilbert space is a complete inner product space. Completeness means that every Cauchy sequence in the space converges to a limit within the space. Hilbert spaces are the mathematical framework in which quantum mechanics is formulated.
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Hilbert Space</span>
          <p>
            A Hilbert space \(\mathcal{H}\) is a vector space over the field of complex numbers \(\mathbb{C}\) with an inner product \(\langle \cdot, \cdot \rangle\) such that:
          </p>
          <ol>
            <li>\(\mathcal{H}\) is an inner product space</li>
            <li>\(\mathcal{H}\) is complete with respect to the norm induced by the inner product, i.e., every Cauchy sequence of vectors converges to a vector in \(\mathcal{H}\)</li>
          </ol>
        </div>
        
        <p>
          Hilbert spaces can be finite-dimensional (like \(\mathbb{C}^n\)) or infinite-dimensional (like the space of square-integrable functions \(L^2([a,b])\)). In quantum mechanics, the state space of a quantum system is a Hilbert space, and physical observables are represented by self-adjoint operators on this space.
        </p>
        
        <h3 class="subsection-title"><i class="fas fa-infinity"></i> Infinite-Dimensional Hilbert Spaces</h3>
        
        <p>
          In many quantum mechanical applications, we work with infinite-dimensional Hilbert spaces. A common example is \(L^2(\mathbb{R})\), the space of square-integrable functions on the real line. For \(f, g \in L^2(\mathbb{R})\), the inner product is defined as:
        </p>
        
        <div class="scrollable-math">
          \[\langle f, g \rangle = \int_{-\infty}^{\infty} f^*(x) g(x) \, dx\]
        </div>
        
        <p>
          The condition that \(f\) is square-integrable means:
        </p>
        
        <div class="scrollable-math">
          \[\int_{-\infty}^{\infty} |f(x)|^2 \, dx < \infty\]
        </div>
        
        <div class="math-note">
          <p>
            <strong>Important Note:</strong> In quantum mechanics, the wave function \(\psi(x)\) of a particle must be square-integrable (i.e., \(\psi \in L^2(\mathbb{R})\)) because \(|\psi(x)|^2\) represents the probability density of finding the particle at position \(x\). The total probability must be finite (and typically normalized to 1).
          </p>
        </div>
        
        <h3 class="subsection-title"><i class="fas fa-expand-arrows-alt"></i> Orthonormal Bases in Hilbert Spaces</h3>
        
        <p>
          Every finite-dimensional Hilbert space has an orthonormal basis. For infinite-dimensional Hilbert spaces, we need to consider countably infinite orthonormal sets.
        </p>
        
        <div class="theorem">
          <span class="theorem-title">Theorem: Parseval's Identity</span>
          <p>
            If \(\{e_n\}_{n=1}^{\infty}\) is an orthonormal basis for a Hilbert space \(\mathcal{H}\), then for any vector \(v \in \mathcal{H}\):
            \[||v||^2 = \sum_{n=1}^{\infty} |\langle e_n, v \rangle|^2\]
          </p>
        </div>
        
        <p>
          This theorem generalizes the Pythagorean theorem to infinite dimensions and expresses the fact that the squared norm of a vector equals the sum of the squared absolute values of its components in an orthonormal basis.
        </p>
        
        <div class="example">
          <span class="example-title">Example: Fourier Series</span>
          <p>
            The set of functions \(\{e^{inx}\}_{n=-\infty}^{\infty}\) forms an orthogonal basis for \(L^2([-\pi,\pi])\). Any function \(f \in L^2([-\pi,\pi])\) can be expressed as a Fourier series:
            \[f(x) = \sum_{n=-\infty}^{\infty} c_n e^{inx}\]
            where the Fourier coefficients are given by:
            \[c_n = \frac{1}{2\pi} \int_{-\pi}^{\pi} f(x) e^{-inx} \, dx\]
          </p>
        </div>
      </section>

      <section id="dirac-notation">
        <h2 class="section-title">Dirac Notation</h2>
        
        <p>
          Dirac notation is a powerful and elegant notation system introduced by physicist Paul Dirac that simplifies many calculations in quantum mechanics. It provides a convenient way to represent vectors, dual vectors, and operators in Hilbert spaces.
        </p>
        
        <h3 class="subsection-title"><i class="fas fa-angle-right"></i> Ket Vectors</h3>
        
        <p>
          In Dirac notation, a vector \(v\) in a Hilbert space is denoted by \(|v\rangle\) and called a "ket" vector. For example, in a discrete basis \(\{|n\rangle\}\), a general state \(|\psi\rangle\) can be expressed as:
        </p>
        
        <div class="scrollable-math">
          \[|\psi\rangle = \sum_n c_n |n\rangle\]
        </div>
        
        <p>
          where \(c_n\) are complex coefficients.
        </p>
        
        <h3 class="subsection-title"><i class="fas fa-angle-left"></i> Bra Vectors</h3>
        
        <p>
          The dual vector to \(|v\rangle\) is denoted by \(\langle v|\) and called a "bra" vector. The dual space is the set of all linear functionals (linear maps from the Hilbert space to \(\mathbb{C}\)).
        </p>
        
        <p>
          If \(|v\rangle\) corresponds to a column vector, then \(\langle v|\) corresponds to the conjugate transpose (row vector):
        </p>
        
        <div class="scrollable-math">
          \[\text{If } |v\rangle = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}, \text{ then } \langle v| = \begin{pmatrix} v_1^* & v_2^* & \cdots & v_n^* \end{pmatrix}\]
        </div>
        
        <h3 class="subsection-title"><i class="fas fa-grip-lines"></i> Inner Products and Outer Products</h3>
        
        <p>
          The inner product of two vectors \(|v\rangle\) and \(|w\rangle\) is written as \(\langle v|w\rangle\), which beautifully illustrates the concept of a bra vector acting on a ket vector to produce a scalar:
        </p>
        
        <div class="scrollable-math">
          \[\langle v|w\rangle = \sum_i v_i^* w_i\]
        </div>
        
        <p>
          The outer product \(|v\rangle\langle w|\) represents an operator that maps a vector \(|u\rangle\) to the vector \(\langle w|u\rangle |v\rangle\). In matrix form, if \(|v\rangle\) and \(|w\rangle\) are column vectors, then \(|v\rangle\langle w|\) is the matrix product of a column vector and a row vector:
        </p>
        
        <div class="scrollable-math">
          \[|v\rangle\langle w| = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} \begin{pmatrix} w_1^* & w_2^* & \cdots & w_m^* \end{pmatrix} = \begin{pmatrix} v_1 w_1^* & v_1 w_2^* & \cdots & v_1 w_m^* \\ v_2 w_1^* & v_2 w_2^* & \cdots & v_2 w_m^* \\ \vdots & \vdots & \ddots & \vdots \\ v_n w_1^* & v_n w_2^* & \cdots & v_n w_m^* \end{pmatrix}\]
        </div>
        
        <div class="theorem">
          <span class="theorem-title">Theorem: Resolution of Identity</span>
          <p>
            If \(\{|e_i\rangle\}\) is an orthonormal basis for a Hilbert space \(\mathcal{H}\), then the identity operator \(I\) can be expressed as:
            \[I = \sum_i |e_i\rangle\langle e_i|\]
            This is called the resolution of identity and is a fundamental result in Hilbert space theory.
          </p>
        </div>
        
        <div class="example">
          <span class="example-title">Example: Projection Operators</span>
          <p>
            If \(|v\rangle\) is a unit vector, then \(P = |v\rangle\langle v|\) is a projection operator onto the one-dimensional subspace spanned by \(|v\rangle\):
            \[P|w\rangle = |v\rangle\langle v|w\rangle = \langle v|w\rangle |v\rangle\]
            Note that \(P^2 = P\) and \(P^\dagger = P\), which are defining properties of projection operators.
          </p>
        </div>

        <div class="math-note">
          <p>
            <strong>Dirac Notation Elegance:</strong> One of the most appealing aspects of Dirac notation is the way it allows us to express complex operations in a clear, concise manner. For example, the action of an operator \(A\) on a state \(|\psi\rangle\) is simply written as \(A|\psi\rangle\), and the expectation value of an observable \(A\) in the state \(|\psi\rangle\) is \(\langle\psi|A|\psi\rangle\).
          </p>
        </div>
      </section>

      <section id="linear-operators">
        <h2 class="section-title">Linear Operators</h2>
        
        <p>
          Linear operators are mappings between vector spaces that preserve vector addition and scalar multiplication. In quantum mechanics, physical observables are represented by linear operators acting on Hilbert spaces.
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Linear Operator</span>
          <p>
            A linear operator \(T: V \rightarrow W\) between vector spaces \(V\) and \(W\) is a map that satisfies:
          </p>
          <ol>
            <li>\(T(u + v) = T(u) + T(v)\) for all \(u, v \in V\)</li>
            <li>\(T(au) = aT(u)\) for all \(a \in \mathbb{C}\) and \(u \in V\)</li>
          </ol>
        </div>
        
        <p>
          In finite dimensions, a linear operator can be represented by a matrix. If \(\{|e_i\rangle\}\) is a basis for \(V\) and \(\{|f_j\rangle\}\) is a basis for \(W\), then the matrix elements of \(T\) are given by:
        </p>
        
        <div class="scrollable-math">
          \[T_{ji} = \langle f_j|T|e_i\rangle\]
        </div>
        
        <h3 class="subsection-title"><i class="fas fa-exchange-alt"></i> Adjoint Operators</h3>
        
        <p>
          For an operator \(A\) on a Hilbert space, the adjoint operator \(A^\dagger\) is defined by:
        </p>
        
        <div class="scrollable-math">
          \[\langle v|A|w\rangle = \langle A^\dagger v|w\rangle\]
        </div>
        
        <p>
          for all vectors \(|v\rangle\) and \(|w\rangle\). In matrix representation, \(A^\dagger\) is the conjugate transpose of \(A\):
        </p>
        
        <div class="scrollable-math">
          \[(A^\dagger)_{ij} = (A_{ji})^*\]
        </div>
        
        <div class="definition">
          <span class="definition-title">Definition: Special Classes of Operators</span>
          <ul>
            <li><strong>Self-adjoint (Hermitian) operator:</strong> \(A = A^\dagger\)</li>
            <li><strong>Normal operator:</strong> \(AA^\dagger = A^\dagger A\)</li>
            <li><strong>Unitary operator:</strong> \(UU^\dagger = U^\dagger U = I\)</li>
            <li><strong>Positive operator:</strong> \(\langle v|A|v\rangle \geq 0\) for all \(|v\rangle\)</li>
            <li><strong>Projection operator:</strong> \(P^2 = P\) and \(P = P^\dagger\)</li>
          </ul>
        </div>
        
        <p>
          Self-adjoint operators are particularly important in quantum mechanics because they represent physical observables. Their eigenvalues are real, corresponding to the possible outcomes of measurements.
        </p>
        
        <div class="theorem">
          <span class="theorem-title">Theorem: Spectral Theorem</span>
          <p>
            Every self-adjoint operator \(A\) on a finite-dimensional Hilbert space can be diagonalized by an orthonormal basis of eigenvectors:
            \[A = \sum_i \lambda_i |i\rangle\langle i|\]
            where \(\lambda_i\) are the eigenvalues of \(A\) and \(|i\rangle\) are the corresponding eigenvectors.
          </p>
        </div>
        
        <p>
          This theorem extends to certain classes of operators on infinite-dimensional Hilbert spaces, but the formulation becomes more technical.
        </p>
      </section>

      <section id="eigenvectors">
        <h2 class="section-title">Eigenvalues and Eigenvectors</h2>
        
        <p>
          Eigenvalues and eigenvectors are fundamental concepts in linear algebra that have profound implications in quantum mechanics. They provide the mathematical foundation for understanding the discrete nature of quantum measurements.
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Eigenvector and Eigenvalue</span>
          <p>
            An eigenvector of a linear operator \(A\) is a non-zero vector \(|v\rangle\) such that:
            \[A|v\rangle = \lambda |v\rangle\]
            for some scalar \(\lambda\), which is called the eigenvalue corresponding to \(|v\rangle\).
          </p>
        </div>
        
        <p>
          The set of all eigenvalues of an operator is called its spectrum. For a linear operator on an \(n\)-dimensional vector space, the characteristic equation:
        </p>
        
        <div class="scrollable-math">
          \[\det(A - \lambda I) = 0\]
        </div>
        
        <p>
          is a polynomial equation of degree \(n\) whose roots are the eigenvalues of \(A\).
        </p>
        
        <div class="theorem">
          <span class="theorem-title">Theorem: Properties of Eigenvalues and Eigenvectors</span>
          <ul>
            <li>If \(A\) is self-adjoint (Hermitian), then all its eigenvalues are real.</li>
            <li>If \(A\) is self-adjoint, then eigenvectors corresponding to distinct eigenvalues are orthogonal.</li>
            <li>If \(U\) is unitary, then all its eigenvalues have modulus 1, i.e., they are of the form \(e^{i\theta}\) for some real \(\theta\).</li>
            <li>If \(A\) is normal (\(AA^\dagger = A^\dagger A\)), then it has a complete set of orthonormal eigenvectors.</li>
          </ul>
        </div>
        
        <div class="example">
          <span class="example-title">Example: Diagonalization of a Matrix</span>
          <p>
            Consider the Hermitian matrix:
            \[A = \begin{pmatrix} 2 & 1 \\ 1 & 2 \end{pmatrix}\]
            The characteristic equation is:
            \[\det(A - \lambda I) = (2 - \lambda)^2 - 1 = \lambda^2 - 4\lambda + 3 = 0\]
            which gives eigenvalues \(\lambda_1 = 1\) and \(\lambda_2 = 3\).
          </p>
          <p>
            For \(\lambda_1 = 1\), the eigenvector equation \((A - I)v = 0\) gives:
            \[\begin{pmatrix} 1 & 1 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\]
            This implies \(v_1 = -v_2\). Normalizing, we get the eigenvector:
            \[|v_1\rangle = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ -1 \end{pmatrix}\]
          </p>
          <p>
            Similarly, for \(\lambda_2 = 3\), we get the eigenvector:
            \[|v_2\rangle = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 \\ 1 \end{pmatrix}\]
          </p>
          <p>
            The matrix can be diagonalized as:
            \[A = \begin{pmatrix} \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \\ -\frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 0 & 3 \end{pmatrix} \begin{pmatrix} \frac{1}{\sqrt{2}} & -\frac{1}{\sqrt{2}} \\ \frac{1}{\sqrt{2}} & \frac{1}{\sqrt{2}} \end{pmatrix}\]
            or in Dirac notation:
            \[A = 1 \cdot |v_1\rangle\langle v_1| + 3 \cdot |v_2\rangle\langle v_2|\]
          </p>
        </div>
      </section>

      <section id="tensor-products">
        <h2 class="section-title">Tensor Products</h2>
        
        <p>
          Tensor products are essential for describing composite quantum systems. When two or more quantum systems are combined, the state space of the composite system is the tensor product of the individual state spaces.
        </p>
        
        <div class="definition">
          <span class="definition-title">Definition: Tensor Product of Vector Spaces</span>
          <p>
            The tensor product of two vector spaces \(V\) and \(W\), denoted by \(V \otimes W\), is a vector space whose elements are linear combinations of tensor products of elements from \(V\) and \(W\).
          </p>
        </div>
        
        <p>
          If \(\{|v_i\rangle\}\) is a basis for \(V\) and \(\{|w_j\rangle\}\) is a basis for \(W\), then \(\{|v_i\rangle \otimes |w_j\rangle\}\) is a basis for \(V \otimes W\). Often, the simplified notation \(|v_i\rangle|w_j\rangle\) or \(|v_i, w_j\rangle\) is used for \(|v_i\rangle \otimes |w_j\rangle\).
        </p>
        
        <p>
          The dimension of \(V \otimes W\) is the product of the dimensions of \(V\) and \(W\):
        </p>
        
        <div class="scrollable-math">
          \[\dim(V \otimes W) = \dim(V) \times \dim(W)\]
        </div>
        
        <h3 class="subsection-title"><i class="fas fa-code-branch"></i> Properties of Tensor Products</h3>
        
        <p>
          The tensor product operation has the following properties:
        </p>
        
        <ul>
          <li>Bilinearity: \((a|v_1\rangle + b|v_2\rangle) \otimes |w\rangle = a(|v_1\rangle \otimes |w\rangle) + b(|v_2\rangle \otimes |w\rangle)\) and \(|v\rangle \otimes (c|w_1\rangle + d|w_2\rangle) = c(|v\rangle \otimes |w_1\rangle) + d(|v\rangle \otimes |w_2\rangle)\)</li>
          <li>Associativity: \((U \otimes V) \otimes W \cong U \otimes (V \otimes W)\)</li>
          <li>Inner product: \(\langle v_1 \otimes w_1 | v_2 \otimes w_2 \rangle = \langle v_1 | v_2 \rangle \langle w_1 | w_2 \rangle\)</li>
        </ul>
        
        <h3 class="subsection-title"><i class="fas fa-random"></i> Tensor Products of Operators</h3>
        
        <p>
          If \(A\) is an operator on \(V\) and \(B\) is an operator on \(W\), then \(A \otimes B\) is an operator on \(V \otimes W\) defined by:
        </p>
        
        <div class="scrollable-math">
          \[(A \otimes B)(|v\rangle \otimes |w\rangle) = (A|v\rangle) \otimes (B|w\rangle)\]
        </div>
        
        <p>
          In matrix representation, if \(A\) is an \(m \times n\) matrix and \(B\) is a \(p \times q\) matrix, then \(A \otimes B\) is an \(mp \times nq\) matrix given by:
        </p>
        
        <div class="scrollable-math">
          \[A \otimes B = \begin{pmatrix} 
          a_{11}B & a_{12}B & \cdots & a_{1n}B \\
          a_{21}B & a_{22}B & \cdots & a_{2n}B \\
          \vdots & \vdots & \ddots & \vdots \\
          a_{m1}B & a_{m2}B & \cdots & a_{mn}B
          \end{pmatrix}\]
        </div>
        
        <div class="example">
          <span class="example-title">Example: Tensor Product of Matrices</span>
          <p>
            Consider the matrices:
            \[A = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \quad \text{and} \quad B = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}\]
            The tensor product \(A \otimes B\) is:
            \[A \otimes B = \begin{pmatrix} 
            1 \cdot B & 0 \cdot B \\
            0 \cdot B & 1 \cdot B
            \end{pmatrix} = \begin{pmatrix} 
            0 & 1 & 0 & 0 \\
            1 & 0 & 0 & 0 \\
            0 & 0 & 0 & 1 \\
            0 & 0 & 1 & 0
            \end{pmatrix}\]
          </p>
        </div>
        
        <h3 class="subsection-title"><i class="fas fa-atom"></i> Entanglement</h3>
        
        <p>
          One of the most intriguing aspects of quantum mechanics is entanglement, which is intimately related to tensor products. A pure state \(|\psi\rangle\) in \(V \otimes W\) is called separable if it can be written as \(|\psi\rangle = |v\rangle \otimes |w\rangle\) for some \(|v\rangle \in V\) and \(|w\rangle \in W\). Otherwise, it is called entangled.
        </p>
        
        <div class="example">
          <span class="example-title">Example: Bell States</span>
          <p>
            The Bell states are maximally entangled two-qubit states:
            \[|\Phi^+\rangle = \frac{1}{\sqrt{2}}(|0\rangle \otimes |0\rangle + |1\rangle \otimes |1\rangle) = \frac{1}{\sqrt{2}}(|00\rangle + |11\rangle)\]
            \[|\Phi^-\rangle = \frac{1}{\sqrt{2}}(|0\rangle \otimes |0\rangle - |1\rangle \otimes |1\rangle) = \frac{1}{\sqrt{2}}(|00\rangle - |11\rangle)\]
            \[|\Psi^+\rangle = \frac{1}{\sqrt{2}}(|0\rangle \otimes |1\rangle + |1\rangle \otimes |0\rangle) = \frac{1}{\sqrt{2}}(|01\rangle + |10\rangle)\]
            \[|\Psi^-\rangle = \frac{1}{\sqrt{2}}(|0\rangle \otimes |1\rangle - |1\rangle \otimes |0\rangle) = \frac{1}{\sqrt{2}}(|01\rangle - |10\rangle)\]
            These states cannot be expressed as tensor products of individual qubit states, demonstrating genuine quantum entanglement.
          </p>
        </div>
        
        <div class="math-note">
          <p>
            <strong>Tensor Products and Quantum Computing:</strong> Tensor products are essential in quantum computing, where the state space of an \(n\)-qubit system is the tensor product of \(n\) 2-dimensional spaces. This structure leads to the exponential growth of the state space with the number of qubits, which is a key feature enabling the potential computational advantage of quantum computers.
          </p>
        </div>
      </section>

      <section>
        <h2 class="section-title">Conclusion and Further Reading</h2>
        
        <p>
          In this note, we have explored the fundamental mathematical structures underlying quantum mechanics. From complex numbers to Hilbert spaces, from linear operators to tensor products, these mathematical tools provide the framework necessary to formulate and understand quantum phenomena.
        </p>
        
        <p>
          The mathematics presented here is both elegant and powerful. It allows us to move beyond classical intuition and describe the quantum world in precise, rigorous terms. As we progress to more advanced topics in quantum mechanics, these mathematical foundations will serve as the building blocks for understanding phenomena such as quantum entanglement, superposition, and measurement.
        </p>
        
        <div class="math-note">
          <p>
            <strong>Recommended Reading:</strong> For those interested in delving deeper into the mathematical foundations of quantum mechanics, the following resources are highly recommended:
          </p>
          <ul>
            <li>John von Neumann, "Mathematical Foundations of Quantum Mechanics"</li>
            <li>Paul A. M. Dirac, "The Principles of Quantum Mechanics"</li>
            <li>Michael A. Nielsen and Isaac L. Chuang, "Quantum Computation and Quantum Information"</li>
            <li>Brian C. Hall, "Quantum Theory for Mathematicians"</li>
            <li>Jiří Blank, Pavel Exner, and Miloslav Havlíček, "Hilbert Space Operators in Quantum Physics"</li>
          </ul>
        </div>
      </section>

      <div class="note-navigation">
        <a href="0.introduction_to_quantum_mechanics.html" class="nav-link nav-prev">
          <i class="fas fa-arrow-left"></i>
          <div class="nav-text">
            <span class="nav-label">Previous</span>
            <span class="nav-title">Introduction to Quantum Mechanics</span>
          </div>
        </a>
        <a href="10.quantum_states_and_operators.html" class="nav-link nav-next">
          <div class="nav-text">
            <span class="nav-label">Next</span>
            <span class="nav-title">Quantum States and Operators</span>
          </div>
          <i class="fas fa-arrow-right"></i>
        </a>
      </div>
    </div>
  </div>

  <footer>
    <p>© <script>document.write(new Date().getFullYear())</script> Quantum Notes</p>
  </footer>

  <!-- Scripts -->
  <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
  
  <!-- KaTeX rendering -->
  <script>
    document.addEventListener("DOMContentLoaded", function() {
      renderMathInElement(document.body, {
        delimiters: [
          {left: "$", right: "$", display: true},
          {left: "\\[", right: "\\]", display: true},
          {left: "$", right: "$", display: false},
          {left: "\\(", right: "\\)", display: false}
        ],
        throwOnError: false
      });
    });
  </script>

  <script>
    // Smooth scrolling for anchor links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        
        document.querySelector(this.getAttribute('href')).scrollIntoView({
          behavior: 'smooth'
        });
      });
    });
  </script>
</body>
</html>